## Old to be deleted. 
## Replaced with 01-prepare.R

# Set up Station Data {#Setup4}

```{r tidyr4, echo = FALSE, message = FALSE, warning = FALSE}

library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=50), tidy = FALSE)

```

Originally the code was looping through both sites and species. However, because the analysis sometimes fails for a given species, the following code will have to be run for each station separately, and then we loop through species to apply the analysis. You will have to keep track of which row in the analysis parameters file a site corresponds to.

## Choose the Site {#Setup4.1}

The number assigned to `t` will correspond to the row in the analysis parameters file ('anal.param') you want to analyze (each site has a separate row).

Also, assign values to the R objects for collection, station, site, and whether the analysis should be site-specific or not, based on values in the 'anal.param' file. The latter (site.specific) is relevant only for LPBO currently, which has three sites. Typically, data are combined across sites for the analysis, and site-specific is FALSE.

```{r chooseSite}

#######
# This is the only thing that needs to be changed in this file:
# number based on anal.param
t <- 1
#######

collection <- as.character(anal.param[t, "collection"])
station <- as.character(anal.param[t, "station"])
site <- as.character(anal.param[t, "site"])
site.specific <- anal.param[t, "site.specific"]
min.species <- anal.param[t, "min.species"]
use.trfl <- anal.param[t, "use.trfl"]

# do not post trends to web for following sites:
# at next analysis (up to 2018), TLBBS should have enough data to go online
# also at next analysis (up to 2018), HBO-ROCK, ATBP, and DMBO need not be analyzed (no longer collecting data)

if(site %in% c("TLBBS", "HBO-ROCK", "HBO-SELK", "ATBP", "DMBO")) {
  
write.indices.sql = FALSE
write.trends.sql = FALSE
}

```

## Import Data

Import data for a station (all species, sites, seasons) using the naturecounts R package. 

```{r importData}

in.data <- nc_data_dl(collections = collection, fields_set = "extended", username = "dethier", info="Trend analysis", years=c(2011, 2021))

in.data <- in.data %>% select(SurveyAreaIdentifier, project_id, ObservationCount, ObservationCount2, ObservationCount3, ObservationCount4, SiteCode, YearCollected, MonthCollected, DayCollected, species_id, SpeciesCode)

# we only want sites LPBO1, LPBO2, and LPBO3. 
if(station == "LPBO") {
in.data <- in.data %>%
  distinct() %>%
  filter(SurveyAreaIdentifier != "LPBO-03") %>% 
  droplevels()
}

# this should be fixed in the underlying data - I sent note to Catherine March 5/2018
if(station == "IBS") {
  in.data <- in.data %>%
  mutate(ObservationCount4 = if_else(is.na(ObservationCount4), ObservationCount, condition = ObservationCount4))
}

## for HBO and OOT, which have more than one station, but where station(s) need to be dropped, we do the following:
if((station == "HBO"|station == "OOT"|station == "ABO")) {
  in.data <- in.data %>%
  filter(SurveyAreaIdentifier == site) %>%
  droplevels()
}

# This is a fix while Catherine is away - there are two names for this site VLMMS 2001-2015, and VLBO 2016-2017 which I believe should be same site, so rename
if((station == "VLBO")) {
  in.data <- in.data %>%
  mutate(SurveyAreaIdentifier = "VLBO") %>%
  droplevels()
}

## Generate site list - this will have a length of 1 for most sites; at LPBO will include all three sites

site.list <- as.character(unique(in.data$SurveyAreaIdentifier))

# DROP BAD DATES:drop days that should be excluded from a site for one reason or another.  We do this again later to drop species-specific bad dates.

# Note: I made some manual tweaks to the function. Need to check that it works for all sites. 
in.data <- bscdata.filterBadDates(in.data, sitecode = site.list)

## Assign date and season variables
in.data <- in.data %>%
    mutate(date = ymd(paste(YearCollected, MonthCollected, DayCollected, sep = "/")),
           doy = yday(date),
           season = if_else(doy < 180, "Spring", "Fall"))
  
```

## Subset data to specified MAX (long-term) year range

If min and max year are specified in anal.param, use those, otherwise use min and max year in dataframe.  For max year, we assign the year specified above in max.year, if an earlier year isn't specified in anal.param.

```{r yearRange}

# note that this assumes that if stations that are no longer collecting are to be analyzed, that the last year is specified in the anal.param table:

min.yr.filt <- ifelse(is.na(anal.param[t,"min.year"]),
                      min(in.data$YearCollected), anal.param[t,"min.year"])

max.yr.filt <- ifelse(is.na(anal.param[t,"max.year"]),
                      max.year, anal.param[t,"max.year"])

# Subset data to specified year range

in.data <- in.data %>%
  filter(YearCollected >= min.yr.filt & YearCollected <= max.yr.filt)

print("year range:"); print(range(in.data$YearCollected))

# get the minimum number of years a species must be detected to be included. Could be MUCH more conservative... currently using 1/2 of years surveyed, but those species might also get kicked out by abundance filters below.

min.yrs.detect <- trunc(length(unique(in.data$YearCollected))/2) 

# total number of years each doy surveyed at each site (include 0-obs counts)
# this will be used later in species-specific loop to calculate proportion of years observed
  
  df.totYears <- in.data %>%
    select(SurveyAreaIdentifier, YearCollected, doy) %>%
    distinct() %>%
    group_by(SurveyAreaIdentifier, doy) %>%
    summarize(totYears = n()) %>%
    as.data.frame()

```

## Calculate season-specific station windows (when a station normally operates)

We determine the inner 95%ile of dates when a station is operational across years, to remove dates at the beginning or end of the migration season that aren't typically monitored.

```{r siteWindows}

## the following gets the start and end dates for each station and season
## uses the observation variable that is being analyzed, 

df.sampleDates <- in.data %>%
  select(SurveyAreaIdentifier, season, YearCollected, doy, as.character(anal.param[t , "obs.var"])) %>%
  group_by(SurveyAreaIdentifier, season, YearCollected, doy) %>%
  summarize(nspecies = n()) %>%
  filter(nspecies >= min.species) %>% # at least 10 individuals observed, usually
  group_by(SurveyAreaIdentifier, season) %>%
  summarize(
    start_doy = round(quantile(doy, probs = c(station.pctile1, station.pctile2)/100, 
		na.rm = TRUE), digits = 0)[[1]],
		end_doy = round(quantile(doy, probs = c(station.pctile1, station.pctile2)/100, 
		na.rm = TRUE), digits = 0)[[2]])
  
## filter main data frame by migration windows
## we do this by merging and dropping observations outside the start and end dates
  
in.data <- left_join(in.data, df.sampleDates, by = c("SurveyAreaIdentifier", "season")) %>%
  filter(doy >= start_doy, doy <= end_doy) %>%
  select(-start_doy, -end_doy)

```

## Make list of sampling dates for zero-filling

Make a list of unique sampling dates (excluding bad dates above) to use for zero-filling species-specific dataframes. We don't zero-fill the entire dataframe for space issues (LPBO has too many years, sites, and it crashes/takes up too much memory)

```{r samplingEvents}

event.data <- in.data %>%
  filter(as.character(anal.param[t , "obs.var"]) > 0) %>%
  group_by(SurveyAreaIdentifier, YearCollected, MonthCollected, DayCollected, date, doy, season) %>%
  mutate(nspecies = n()) %>%
  filter(nspecies > min.species) %>% # assuming at least one individual detected each day. This could be modified, for example, to include only dates when at least 10 species were detected.
  select(SurveyAreaIdentifier, YearCollected, MonthCollected, DayCollected, date, doy, season) %>% 
  distinct() %>%
  ungroup() %>%
  as.data.frame()
 
```


## Assign Species Code, and drop species that won't be analyzed

Because speciesIDs often change with updates to taxonomies, we want to use the species codes assigned during data entry, and update the speciesIDs in the data accordingly. 

There are also species that need to be combined for analysis. The following species have subspecies, etc, that should be analyzed as one species. Prior to analysis, we need to re-assign species codes so that they match the primary code (EATO, GCTH, etc).  Denis may have fixed some in database (e.g. WISN), but won’t hurt to keep in script until we’re sure:

EATO: 18560, 18570 (RSTO, URST, EATO)
GCTH: 15551, 15560, 15570 (GBTH, GCBT, GCTH, BITH)
NSTS: 18940, 18961 (NESP, STSP, NSTS)
SOVI: 13390, 13410, 13420 (SOVI, CAVI, BHVI)
TRFL: 12150, 12160, 12170 (TRFL, ALFL, WIFL)

WEFL: 12231, 12240 (WEFL, PSFL)
WISN: 4940, 4950 (WISN, COSN)
WPWI: 7870, 7871 (WPWI, EWPW, EWWP)

At the end of this section, we add the counts for a given species/dates, in case e.g., BHVI, SOVI were recorded on the same date, there will now be two records for SOVI on that date. We want the total count across these records.

```{r assignSpCode}

## print list of SpeciesCodes with NA species_ids. This is more for interest sake. These are likely species codes that were entered incorrectly. Unless there is a large amount of them, ignore.

  print(paste("Species Codes with no species_id: "))
  filter(in.data, is.na(species_id)) %>% 
    select(SpeciesCode) %>%
    group_by(SpeciesCode) %>%
    summarize(n = n()) %>% 
    arrange(n) %>% 
    select(SpeciesCode, n) %>% 
    as.data.frame()

## re-assign species codes
  
  in.data %>% filter(SpeciesCode %in% c("SOVI", "EATO", "NSTS", "TRFL", "WEFL", "WISN", "NOFL", "WPWI", "PAWA","DEJU","YRWA")) %>%
    group_by(SpeciesCode) %>%
    tally()
  
  in.data <- in.data %>%
    mutate(SpeciesCode = as.character(SpeciesCode),
           SpeciesCode = replace(SpeciesCode, (SpeciesCode == "BHVI"|SpeciesCode == "CAVI"), "SOVI"),
           SpeciesCode = replace(SpeciesCode, (SpeciesCode == "YEWA"), "YWAR"),
           SpeciesCode = replace(SpeciesCode, (SpeciesCode == "RSTO"|SpeciesCode == "URST"), "EATO"),
           SpeciesCode = replace(SpeciesCode, (SpeciesCode == "GBTH"|SpeciesCode == "GCBT"|SpeciesCode == "BITH"), "GCTH"),
           SpeciesCode = replace(SpeciesCode, (SpeciesCode == "NESP"|SpeciesCode == "STSP"), "NSTS"),
           SpeciesCode = replace(SpeciesCode, (SpeciesCode == "ALFL"|SpeciesCode == "WIFL"), "TRFL"),
           SpeciesCode = replace(SpeciesCode, (SpeciesCode == "GWCS"|SpeciesCode == "EWCS"), "WCSP"),
           SpeciesCode = replace(SpeciesCode, (SpeciesCode == "AGWT"), "GWTE"),
           SpeciesCode = replace(SpeciesCode, (SpeciesCode == "PSFL"), "WEFL"),
           SpeciesCode = replace(SpeciesCode, (SpeciesCode == "COSN"), "WISN"),
           SpeciesCode = replace(SpeciesCode, (SpeciesCode == "YSFL"|SpeciesCode == "FLIN"), "NOFL"),
           SpeciesCode = replace(SpeciesCode, (SpeciesCode == "EWPW"|SpeciesCode == "EWWP"), "WPWI"),
           SpeciesCode = replace(SpeciesCode, (SpeciesCode == "WPWA"|SpeciesCode == "UNPW"|SpeciesCode == "YPWA"), "PAWA"),
           SpeciesCode = replace(SpeciesCode, (SpeciesCode == "UYRW"|SpeciesCode == "MYWA"|SpeciesCode == "AUWA"), "YRWA"),
           SpeciesCode = replace(SpeciesCode, (SpeciesCode == "SCJU"|SpeciesCode == "GHJU"|SpeciesCode == "ORJU"|SpeciesCode == "UDEJ"|SpeciesCode == "WWJU"|SpeciesCode == "YDEJ"|SpeciesCode == "PSJU"), "DEJU"))
    
  in.data %>% filter(SpeciesCode %in% c("SOVI", "EATO", "NSTS", "TRFL", "WEFL", "WISN", "NOFL", "WPWI", "PAWA","DEJU","YRWA")) %>%
    group_by(SpeciesCode) %>%
    tally()
  
## re-assign speciesID based on the new species codes
## This ensures species codes/ids are consistent across stations and
## years/days within a station
  
  sp.list1 <- select(in.data, SpeciesCode) %>%
                  distinct()
  
  sp.code<-search_species_code()
  
  sp.list <- left_join(sp.list1, sp.code, by = c("SpeciesCode" = "BSCDATA")) %>%
    filter(!is.na(SpeciesCode))

  in.data <- left_join(select(in.data, -species_id), sp.list, by = "SpeciesCode") %>%
    filter(!is.na(species_id))
    

## get total count by species, date, station
  
  in.data$ObservationCount<-as.numeric(in.data$ObservationCount)
  in.data$ObservationCount2<-as.numeric(in.data$ObservationCount2)
  in.data$ObservationCount3<-as.numeric(in.data$ObservationCount3)
  in.data$ObservationCount4<-as.numeric(in.data$ObservationCount4)
  
  in.data <- in.data %>%
    group_by(SurveyAreaIdentifier, YearCollected, MonthCollected, DayCollected, SpeciesCode, species_id, date, doy, season) %>%
    dplyr::summarize(ObservationCount = sum(ObservationCount, na.rm = TRUE),
              ObservationCount2 = sum(ObservationCount2, na.rm = TRUE),
              ObservationCount3 = sum(ObservationCount3, na.rm = TRUE),
              ObservationCount4 = sum(ObservationCount4, na.rm = TRUE)) %>%
    as.data.frame()

```  
  
## Read in Superfile

In 2017, Ricky developed a 'superfile' which classifies species as migrant or other, determines whether they should be included in trend analysis, and gives the migration windows for each species at each station.  Only species classified as migrant ('M') should have trends displayed on the web, however, trends for all species are calculated and output for internal/station use.

```{r readSuperfile}

df.superfile <- read.csv("Data/CMMNSuperfile.csv")
df.superfile <- filter(df.superfile, project_id == project) %>%
  mutate(SurveyAreaIdentifier = SiteCode,
         SpeciesCode = species_code,
         season = period) %>%
  select(-SiteCode, -species_code, -period) %>%
  filter(include == 1, !(analysis_code == "R"), SurveyAreaIdentifier %in% site.list) %>%
  droplevels()
  
  # this file currently only contains CMMN data, but might contain other projects eventually, so we restrict to 1005.

```

```{r filterWithSuperfile}

## Use the superfile to filter to species and season of interest
  
sp.analyze <- df.superfile %>%
  select(SurveyAreaIdentifier, SpeciesCode, season, start_date, end_date, analysis_code, lpbo_combine) %>%
  distinct() %>%
  droplevels()

in.data <- left_join(sp.analyze, in.data, by = c("SurveyAreaIdentifier", "SpeciesCode", "season")) %>%
  droplevels()


## determine number of species at each station
  tmp <- in.data %>%
    select(SurveyAreaIdentifier, season, SpeciesCode) %>%
    distinct() %>%
    group_by(SurveyAreaIdentifier, season) %>%
    summarize(nspecies = n())
  
  print("Number of species at each site")
  print(tmp)
  
```

## Run 'Assign UNEM.R' For LPBO data only!!!  

This section modifies empidonax values by assigning unknown empidonax to  LEFL, YBFL, TRFL by the proportional representation of each species on each doy (across years) in ET data. Might use banding data (ObservationCount4), but not available digitally pre-1984. NOTE that by running this, banding data and census data are erased from in.data for empid species. Do not include ACFL because there as so few it would make little impact.

Tara: I really don't like this whole thing. Filters down from David Hussell's days, but seems inconsistent. Would be better to model the relationship and use those probabilities instead of raw, which can jump from day to day [TO DO]

NOTE: if analyzing census data for LPBO, might want to consider doing the same thing as below for census data...

if(anal.param[t, "assign.empid"] == TRUE) {
  in.data <- assign.unem(in.data = in.data, project = project,
 	collection = as.character(anal.param[t, "band"]), obs.var = as.character(anal.param[t, "obs.var"]))   } 

in.data <- droplevels(subset(in.data, SpeciesCode != "UNEM"))

```{r assignUNEM}

## Empidonax are coded as UNEM, LEFL, YBFL, ALFL, WIFL

if(site == "LPBO") {

## 1. summarize the total of known empidonax species by doy/site, across years

df.empidSum <- in.data %>%
  filter(SpeciesCode %in% c("LEFL", "YBFL", "TRFL")) %>%
  group_by(SurveyAreaIdentifier, doy) %>%
  summarize(KnownEmpidET = sum(ObservationCount, na.rm = TRUE),
            KnownEmpidCensus = sum(ObservationCount4, na.rm = TRUE))

## 2. summarize total of each empid species by doy/site, across years

df.empidSum2 <- in.data %>%
  filter(SpeciesCode %in% c("LEFL", "YBFL", "TRFL")) %>%
  group_by(SurveyAreaIdentifier, doy, SpeciesCode) %>%
  summarize(totET = sum(ObservationCount, na.rm = TRUE),
            totCensus = sum(ObservationCount4, na.rm = TRUE))

##3. merge to get proportion of total empid for each species by site, doy

df.empidSum <- left_join(df.empidSum, df.empidSum2, by = c("SurveyAreaIdentifier", "doy")) %>%
  mutate(p.totET = totET/KnownEmpidET,
         p.totCensus = totCensus/KnownEmpidCensus) %>%
  select(SurveyAreaIdentifier, doy, SpeciesCode, p.totET, p.totCensus)

#ggplot(df.empidSum, aes(y = p.tot, x = doy, colour = SpeciesCode)) + geom_point()

##4. merge this with total number of unknown empidonax

df.unem <- in.data %>%
  filter(SpeciesCode %in% c("UNEM")) %>%
  group_by(SurveyAreaIdentifier, YearCollected, MonthCollected, DayCollected, date, doy) %>%
  summarize(totUNEMET = sum(ObservationCount, na.rm = TRUE),
            totUNEMCensus = sum(ObservationCount4, na.rm = TRUE)) %>%
  left_join(df.empidSum, by = c("SurveyAreaIdentifier","doy")) %>%
  mutate(addObsET = round(totUNEMET*p.totET, digits = 0),
         addObsCensus = round(totUNEMCensus*p.totCensus, digits = 0)) %>%
  as.data.frame() %>%
  select(-totUNEMET, -totUNEMCensus,-p.totET, -p.totCensus)
           
##5. merge this with the raw data, and sum addObs and ObservationCount

in.data <- left_join(in.data, df.unem, by = c("SurveyAreaIdentifier", "YearCollected", "MonthCollected", "DayCollected", "date", "doy", "SpeciesCode")) %>%
  mutate(addObsET = if_else(is.na(addObsET), 0, addObsET),
         addObsCensus = if_else(is.na(addObsCensus), 0, addObsCensus),
         ObservationCount = ObservationCount + addObsET,
         ObservationCount4 = ObservationCount4 + addObsCensus) %>%
  select(-addObsET, -addObsCensus) %>%
  filter(SpeciesCode != "UNEM")

}
 
```

## Reduce dataset to ObservationCount of interest.  

This step is necessary for IBS and HBO-ROCK, which use banding data instead of DET data to estimate trends.  This is the place where you could modify what count variable you want to analyze.  I.e., instead of specifying "as.character(anal.param[t , "obs.var"])" in the code below, you could specify a particular count type. 

NOTE: ObservationCount = ET, ObservationCount3 = Census, ObservationCount4 = banding.

NOTE: this step might not be necessary if you can input the obs variable right into the analysis. Leaving for now.

```{r pickObservationCountVar}

in.data <- in.data %>% dplyr::select(SurveyAreaIdentifier, YearCollected, MonthCollected, DayCollected, date, doy, season, SpeciesCode, species_id, as.character(anal.param[t , "obs.var"]), start_date, end_date, analysis_code, lpbo_combine) 

# rename count variable, so consistent for following steps

names(in.data)[10] <- c("ObservationCount") 

yr.data <- in.data %>%
  filter(ObservationCount > 0) %>%
  group_by(SpeciesCode, YearCollected, season) %>%
  summarize(totCount = sum(ObservationCount),
            nobs = n())



```
